function results = niak_test_diff(data,opt)
%
% _________________________________________________________________________
% SUMMARY NIAK_TEST_DIFF
%
% Perform a bootstrap hypothesis test on the significance of the difference 
% between two connectivity measures.
%
% SYNTAX:
% RESULTS = NIAK_TEST_DIFF(DATA,OPT)
%
% _________________________________________________________________________
% INPUTS:
%
% * DATA   
%       (structure) DATA may have multiple entries, and its fields depend 
%       on the choice of the connectivity measure.
%
%     if OPT.MEASURE == 'R' or 'P' :
%           
%       TSERIES
%           (2D array) DATA(j).TSERIES(:,i) is the time series of the ith 
%           region of the jth dataset.
%
%     if OPT.MEASURE == 'afc'
%
%       TSERIES: (2D array) DATA(j).TSERIES(:,i) is the time series of the 
%           ith region of the jth dataset.
%       
%       PART (vector) find(DATA(j).PART==k) is the list of region in 
%           network k for dataset j. In other words, DATA(j).PART(i) is 
%           the number (k) of the network of region i.
%
%       Note that additional arbitrary fields may (should) be present, and 
%       will be used in the description of the tests (see description 
%       OPT.LIST_TEST).
%
% * OPT    
%       (structure) describe the statistical tests to perform on data. The 
%       following fieds will be used :
%
%       MEASURE 
%           (string) the connectivity measure:
%           'R' : simple correlation (region-to-region 
%                 functional connectivity).
%           'P' : partial correlation, 
%           'afc' : average functional connectivity (or correlation) 
%                   between/within networks.
%
%       LIST_TEST 
%           (structure) describe which differences will be 
%           investigated in the test. Each entry correspond to one 
%           test, with the following list of fields (see the help 
%           of NIAK_FIND_STRUCTS for details) :
%   
%           TAG 
%               (cell of strings, default {'all_tests'}) when requesting for a
%               false-discovery rate estimation, this estimation will
%               apply on a group of test, which are selected by one tag. 
%               Multiple tags can apply to one test.
%
%           DATASET 
%               (structure) Each entry is used to select one or multiple 
%               entries of DATA using two fields. The test will investigate 
%               the difference DATASET(2) - DATASET(1).
%
%               LIST_FIELD 
%                   (cell of strings) which refer to user-defined fields 
%                   of DATA
%               
%               LIST_VAL 
%                   (cell) described the acceptable values of the 
%                   corresponding field.        
%
%       BOOTSTRAP 
%           (structure, omitted fields will be assigned a default 
%           value) with the following fields :
%
%           NULL 
%               (string, default 'duplicate') the constraint added in
%               the bootstrap resampling scheme to force the bootstrap 
%               samples to conform with the null hypothesis. Available
%               options:
%               'duplication' : the same data is used to generate both
%                  bootstrap samples to derive the difference. Time series
%                  are re-generated independently. In group differences, the
%                  sample of datasets are re-generated independently for
%                  each term of the difference.
%               'paired_duplication' : the same data is used to generate both
%                  terms of the difference. Time series
%                  are re-generated independently. In group differences, the
%                  same samples of datasets are used for each term of the 
%                  difference.
%               'mixture' : Each bootstrap sample is generated by actually
%                  mixing the original data from each term of the difference. 
%                  In group differences, the datasets are sampled 
%                  independently for each term.
%               'paired_mixture' : Each term of the data is generated by actually
%                  mixing the original data. In group differences, the
%                  same datasets are used for each term.
%
%           DGP 
%               (string, default 'CBB') the data-generating process used 
%               to derive bootstrap samples.
%               'CBB' (recommended for time series), 'AR1B', 'AR1G', 'iidB'
%
%           if BOOTSTRAP.DGP == 'CBB' :
%
%           WW 
%               (integer, default []) window width used in the circular 
%               block bootstrap. If WW is empty, NIAK_CHOOSE_BLOCK_LENGTH 
%               is used to select the block length.
%
%           NB_SAMPS
%               (vector, default 1000000) number of samples used to 
%               approximate the simple bootstrap estimate of the 
%               false-positive rate, or per-comparison error (PCE).
%
%           NB_ITERATIONS
%               (1 or 2, default 2) If NB_ITERATIONS==1, the
%               false-positive rate is estimated through simple bootstrap. 
%               If NB_ITERATIONS==2, the Yet-Another-Double-Bootstrap 
%               correction is appied.
%
%           NB_SAMPS_ITER
%               (integer, default [10000 1000]) number of bootstrap samples 
%               for the first and second level of bootstrap iteration.
%
%       FLAG_FDR 
%           (boolean, default 1) if the flag is 1, the FDR as a function 
%           of the marginal FPR threshold will be estimated for the group 
%           of tests marked with this tag.
%
%       FLAG_VERBOSE 
%           (boolean, default 1) print messages to indicate which 
%           computation are being done.
%
% _________________________________________________________________________
% OUTPUTS:
%
% * RESULTS       
%       (structure) with the following fields :
%
%       OPT
%           (structure) the options used to derive the test
%
%       INFO
%           (string) description of the toolbox version and the date.
%
%       BINS_MEASURE
%           (vector) the bins used on the connectivity measure to estimate 
%           the PCE.
%
%       BINS_PCE
%           (vector) the bins used on the PCE to estimate the FDR.
%
%       FDR_DIST   
%           (structure) Each field of FDR_DIST is a matrix estimated 
%           for the associated group of tests (see TEST field). 
%           FDR_DIST(i,j) is the False discovery rate for a two-sided 
%           hypothesis against the null hypothesis with a threshold on 
%           marginal false-positive rate BINS_PCE(i), after j
%           iteration of the bootstrap.
%
%       TESTS
%           a structure whose entries correspond to the tests
%           for each difference.
%
%           DATASET1
%               (structure) the first set of entries of data 
%               used to compute the difference
%               "measure(DATASET2)-measure(DATASET1)". Fields used to
%               compute the connectivity measures have been suppressed, and
%               a new field MEASURE has been added, which contains the
%               plugin estimate of connectivity measure.
%
%           DATASET2 
%               (structure) the second set of entries of data used to 
%               compute the difference "measure(DATASET2)-measure(DATASET1)".  
%               Fields used to compute the connectivity measures have been 
%               suppressed, and a new field MEASURE has been added, which 
%               contains the plugin estimate of connectivity measure.
%
%           DIFF 
%              (structure) the difference of connectivity measures.
%
%           PCE(k)  
%              (structure) PCE(k) is the false-positive rate p 
%              for a two-sided hypothesis against
%              the null hypothesis of identical distributions of 
%              the connectivity measures after k iteration of 
%              the bootstrap. PCE is formatted in the same way
%              as a non-vector measure (see NIAK_VEC2COMP)
%
%           MEDIAN  
%               (structure) The median bootstrap estimate of the connectivity
%               measure. Because the bootstrap distribution is forced to
%               conform to the null hypothesis of no connectivity
%               differences, the median should roughly be zero. MEDIAN 
%               is formatted in the same way as a non-vector 
%               measure (see NIAK_VEC2COMP).
% 
%           TAG  
%               (string) the tag of the test.
%  
%           CDF   
%               (matrix) cdf(:,j,k) is the bootstrap cdf of the jth 
%               component after k bootstrap iteration, evaluated on 
%               BINS_MEASURE.
%
%           STD  
%               (vector) std(k) is an estimate of the standard deviation
%               of the bootstrap distribution of differences under the null 
%               hypothesis after k iteration.
%
% _________________________________________________________________________
% SEE ALSO:
%
% NIAK_TABLE_TEST
%
% _________________________________________________________________________
% TODO : 
%
% 1. Make sure the function applies to data with different T
% 2. Correct the computational trick
% 3. Change the measure grid to [-2,2] for AFC (and add that to the list of
%    parameters).
% 4. Extend measures to group-level tests
% 5. Add non-bounded measures : integration and variance. Find a trick to
% adapt the grid for cdf computation.
% 6. Add tests and explicit error message wherever possible.
%
% _________________________________________________________________________
% COMMENTS:
%
% Details about individual bootstrap hypothesis test can be found in the following
% reference:
% P. Bellec; G. Marrelec; H. Benali, 
% A bootstrap test to investigate changes in brain connectivity for 
% functional MRI.
% Statistica Sinica, special issue on Statistical Challenges and Advances 
% in Brain Science.
%
% Here is a short review of possible strategies to set the FDR tags :
%
% 1. The FDR estimated for each test independently can give a very liberal 
% representation of the overall FDR when the tests are actually 
% non-independent. For a given FDR, the associated FPR threshold may vary 
% markedy from one test to the other. This is both good and bad, because on
% one hand it allows to have a very good statistical power for tests 
% with a lot of significant discoveries, but on another hand it is hard to 
% compare the results of tests performed with different statistical power. 
% You can force this strategy by using a different 
% FDR TAG for each test, but this is hardly ever recommended (the different 
% tests usually involve common subsets of DATA, and are therefore very 
% dependent from each other).
%
% 2. Estimate the FDR for all tests taken together. This strategy mat not 
% allow to determine if significant results were achieved for a particular 
% test. The existence of very significant discoveries may allow to achieve 
% a liberal FPR at a reasonable FDR level, and a couple of spurious 
% differences would appear in tests that would not have been regarded as 
% significant if assessed independently. In other words, with a liberal FPR and many 
% significant discoveries, the FDR may be reasonable while the number of 
% expected false-positive is high, making the interpetation of small 
% groups of findings impossible. This is the default behavior.
%
% 3. This last strategy is intermediate between strategies 1 and 2. It
% assumes that some tests are "interesting" and will lead to a large number 
% of discoveries, while others are "non-interesting" and will lead to a 
% few discoveries only. This group classification has to be known in advance. 
% The false-discovery rate (FDR) can be estimated independently for each 
% group of tests. This maximizes the power in "interesting" tests, and 
% limit the number of spurious discoveries in "non-interesting" tests. 
% Tests within a group are performed with the same false-positive rate 
% threshold and are thus readily comparable. 
% Moreover, if results are interpreted within a group, the question of the 
% overall FDR simply does not arise. If a group of tests lead to a very small
% number of discoveries, those can still be interpreted as FDR control gets 
% close to a Bonferroni correction for multiple comparisons in this situation. 
% It is the best scenario, but the grouping information may not be available 
% in a very exploratory analysis. This strategy is implemented by assigning 
% an identical tag to the tests that fall in the same group.
% 
%
% Copyright (c) Pierre Bellec, McConnell Brain Imaging Center,Montreal 
%               Neurological Institute, McGill University, 2008.
% Maintainer : pbellec@bic.mni.mcgill.ca
% See licensing information in the code.
% Keywords : bootstrap, time series, hypothesis testing, functional
% connectivity

% Permission is hereby granted, free of charge, to any person obtaining a copy
% of this software and associated documentation files (the "Software"), to deal
% in the Software without restriction, including without limitation the rights
% to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
% copies of the Software, and to permit persons to whom the Software is
% furnished to do so, subject to the following conditions:
%
% The above copyright notice and this permission notice shall be included in
% all copies or substantial portions of the Software.
%
% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
% AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
% OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
% THE SOFTWARE.

%%%%%%%%%%%%%%%%%%%%%%%%
% set default inputs %%%
%%%%%%%%%%%%%%%%%%%%%%%%

niak_gb_vars

%%% Miscalenous options
gb_name_structure = 'opt';
gb_list_fields = {'measure','list_test','bootstrap','tag_fdr','flag_verbose'};
gb_list_defaults = {NaN,NaN,struct([]),{},1};
niak_set_defaults

%%% Bootstrap options
gb_name_structure = 'opt.bootstrap';
gb_list_fields = {'nb_samps','null','dgp','nb_iterations','nb_samps_iter','ww'};
gb_list_defaults = {1000000,'duplication','CBB',2,[10000 1000],[]};
niak_set_defaults

if strcmp(opt.bootstrap.dgp,'iidB')
    opt.bootstrap.dgp = 'CBB';
    opt.bootstrap.ww = 1;
end

%% If the DGP is circulat block bootstrap, and the length of blocks have
%% not been specified, use the maximum variance criterion to choose the
%% length of th blocks.
if strcmp(opt.bootstrap.dgp,'CBB')&isempty(ww)
    
    if flag_verbose
        fprintf('Estimation of the block length for circular block bootstrap\n');
    end
    opt_block = opt;
    opt_block.bootstrap.nb_iterations = 1;
    opt_block.bootstrap.nb_samps = 1000;
    [hstar,avgr_std,all_std,list_ww] = dnm_select_block_length(tseries,opt_block);
    
    opt.bootstrap.ww = median(hstar);    
    opt.bootstrap.extras.hstar = hstar;
    opt.bootstrap.extras.avgr_std = avgr_std;
    opt.bootstrap.extras.all_std = all_std;
    opt.bootstrap.extras.list_ww = list_ww;
    
end
opt_boot = opt.bootstrap;

%%% Option for cdfs (hard-coded)
bins_measure = -2:0.005:2; % That grid for connectivity measure assumes a measure bounded by -1 and 1
bins_measure = bins_measure(:);

bins_pce =[0]; % That's the grid for the p-values.
for pow = -5:-2
    bins_pce = [bins_pce 10^pow:10^(pow):10^(pow+1)-10^(pow)];
end
bins_pce = [bins_pce 0.1:0.01:0.9 1-bins_pce(end:-1:1)]; % That's the grid for the cdf values.
bins_pce = bins_pce(:);

%% Initializing tag mask for FDR estimation
all_tags = {};
nb_tags = 1;
if ~isfield(list_test,'tag')
    list_test(1).tag = 'all_tests';
end
for num_t = 1:length(list_test)
    if isempty(list_test(num_t).tag)
        list_test(num_t).tag = 'all_tests';
    end
    all_tags = unique([all_tags,list_test(num_t).tag]);
end

mask_tag = logical(zeros(length(list_test),length(all_tags)));
for num_t = 1:length(all_tags)
    mask_tag(:,num_t) = niak_find_structs(list_test,{'tag'},all_tags(num_t));
end
    
    
%%% Printing out the input options in verbose mode

if flag_verbose == 1
    fprintf('\n*********************');
    fprintf('\nEstimation of the significance of difference in connectivity with measure %s.',opt.measure);
    fprintf('A %s bootstrap data-generating process will be used with %i samples and %i iteration(s) to approximate the null hypothesis.',opt.bootstrap.dgp,opt.bootstrap.nb_samps,opt.bootstrap.nb_iterations);
    if nb_iterations > 1
        fprintf('%i samples will be used in level 1 and %i samples in level 2\n',nb_samps_iter(1),nb_samps_iter(2));
    end
    
    if strcmp(dgp,'CBB')
        fprintf('The CBB is performed with a block length of %i.\n',ww);
    end
    
    if length(tag_fdr)>=1
        fprintf('The false-discovery rate as a function of marginal false-positive rate will be estimated for the following group of tests: \n');
        for num_t = 1:length(tag_fdr)
            fprintf('%s ;',tag_fdr{num_t});
        end
        fprintf('\n');
    else
        fprintf('No false-discovery rate will be estimated.\n');
    end        
        
    for num_t = 1:length(all_tags)
        fprintf('\n*********************\n%s\n*********************',all_tags{num_t});
        list2 = list_test(mask_tag(:,num_t));
        for num_e = 1:length(list2);            
            
            fprintf('(');
            for num_f = 1:length(list_test(num_e).dataset(1).list_field)
                fprintf('%s : %s ; ',list_test(num_e).dataset(2).list_field{num_f},list_test(num_e).dataset(2).list_val{num_f});
            end            
            fprintf(') - (');
            for num_f = 1:length(list_test(num_e).dataset(1).list_field)
                fprintf('%s : %s ; ',list_test(num_e).dataset(1).list_field{num_f},list_test(num_e).dataset(1).list_val{num_f});
            end            
            fprintf(')\n');                        
        end
    end    
end

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Initialization of important variables   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% The results structure
results.opt = opt;
results.info = sprintf('Bootstrap test on the significance of difference between connectivity measures. %s',datestr(now));
tic; % We check the computation time;

%%% Set and check dimension informations
nb_data = prod(size(data));

T = zeros([nb_data 1]); 
N = zeros([nb_data 1]);
M = zeros([nb_data 1]);
opt_m.measure = measure;
opt_m.flag_test = 1;
opt_m.flag_vec = 1;

if strcmp(measure,'afc')
    nb_nets = ones([nb_data 1]);
end

for num_e = 1:nb_data
    T(num_e) = size(data(num_e).tseries,1);
    N(num_e) = size(data(num_e).tseries,1);
    M(num_e) = length(niak_build_measure(data(num_e),opt_m));
    if strcmp(measure,'afc')
        part = data(num_e).part;
        nb_nets(num_e) = length(unique(part(part~=0)));
    end
end

nb_tests = size(list_test,1);
clear opt_m

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bootstrap sampling under the null hypothesis of identical %%
% distributions of the connectivity measures.               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% level-1 bootstrap cdf under the null hypothesis

opt_null = opt;
opt_null.bootstrap.nb_iterations = 1;
y = zeros([length(bins_measure) M nb_diffs nb_iterations]);
cdfs(:,:,:,1) = dnm_cdf_null_diffs(tseries,opt_null);

% % Building cdfs under the null
% opt_cdf.bins = bins_measure;
% opt_cdf.low = [-2 0];
% opt_cdf.up = [2 1];
% y = zeros([length(bins_measure) M*nb_diffs nb_iterations]);
% y(:,:,1) = dnm_build_cdf(samps,opt_cdf);
% if flag_T
%     y(:,:,1) = (y(:,:,1) + (1-y(end:-1:1,:,1)))/2;
% end

% Yet Another Double Bootstrap : a correction on first-level bootstrap cdfs is applied

if nb_iterations == 2
       
    nb_samps_iter0 = ceil(nb_samps_iter(1)/2);        
    y2 = zeros([length(bins_measure) M nb_diffs nb_samps_iter0]);

    for num_d = 1:nb_diffs

        num1 = opt_m.diffs(num_d,1);
        num2 = opt_m.diffs(num_d,2);

        for num_s = 1:nb_samps_iter0

            opt_null = opt;
            opt_null.measure.part{1} = opt.measure.part{1};
            opt_null.measure.part{2} = opt.measure.part{1};
            opt_null.measure.diffs = [1 2];

            opt_null.bootstrap.nb_iterations = 1;
            opt_null.bootstrap.nb_samps = ceil(nb_samps_iter(2)/2);

            y_tmp = zeros([length(bins_measure) M 2]);

            for num_seed = 1:2

                opt_null.bootstrap.T_boot = T(num1);
                tseries_boot{1} = dnm_bootstrap_tseries(tseries{opt_m.diffs(num_d,num_seed)},opt_null.bootstrap);
                opt_null.bootstrap.T_boot = T(num2);
                tseries_boot{2} = dnm_bootstrap_tseries(tseries{opt_m.diffs(num_d,num_seed)},opt_null.bootstrap);

                samps2 = dnm_bootstrap_null_diffs(tseries_boot,opt_null);                
                y_tmp(:,:,num_seed) = dnm_build_cdf(samps2,opt_cdf);

                if flag_T
                    y_tmp(:,:,num_seed) = (y_tmp(:,:,num_seed) + (1-y_tmp(end:-1:1,:,num_seed)))/2;
                end
                
            end
            
            y_tmp = mean(y_tmp,3);

            y2(:,:,num_d,num_s) = y_tmp;

        end

    end
    y2 = median(y2,4);
    y2 = reshape(y2,[length(bins_measure) M*nb_diffs]);   
    
    correction_alpha = zeros([length(bins_pce) M*nb_diffs]);
    for num_m = 1:size(y2,2)
        correction_alpha(:,num_m) = interp1(y2(:,num_m),y(:,num_m,1),bins_pce);
        y(:,num_m,2) = interp1(bins_pce,correction_alpha(:,num_m),y(:,num_m,1));
    end
    
end



%%% Deriving the plug-in estimate
theta = dnm_build_diffs_measure(tseries,opt_m);

%%% Deriving the false-positive rate for all tests on differences.

PCEa = zeros([M*nb_diffs nb_iterations]);
PCEb = zeros([M*nb_diffs nb_iterations]);

for num_m = 1:M*nb_diffs
    
    for num_i = 1:nb_iterations
    
        PCEa(num_m,num_i) = interp1(bins_measure,y(:,num_m,num_i),theta(num_m));
        PCEb(num_m,num_i) = 1-PCEa(num_m,num_i);
        
    end
end

PCE = 2*min(PCEa,PCEb);

%%% Deriving estimates of the false-discovery rate are different thresholds

if flag_FDR == 1
    
    % Generating bootstrap samples under the global null, and associated
    % marginal false-positive rate for each iteration of the bootstrap
    samps_glob = dnm_bootstrap_global_null_diffs(tseries,opt);
    
    for num_m = 1:M*nb_diffs
        for num_i = 1:nb_iterations
            PCE_samps(:,num_m,num_i) = interp1(bins_measure,y(:,num_m,num_i),samps_glob(:,num_m));
        end        
    end
    
    % Generating FDR estimates
    FDR_dist = zeros([length(bins_pce),nb_iterations]);
    FDR = zeros([nb_iterations,1]);
    
    for num_i = 1:nb_iterations
        [tmp_FDR,tmp_dist] = dnm_FDR(PCE_samps(:,:,num_i),PCE(:,num_i),bins_pce);
        FDR_dist(:,num_i) = tmp_dist;
        FDR(num_i) = tmp_FDR;
    end
    
end

%% Computing robust std and median
for num_m = 1:size(samps,2)
    %all_std(num_m) = dnm_build_mad(samps(:,num_m));        
    all_std(num_m) = std(samps(:,num_m));        
end
all_median = median(samps,1)';

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Formatting the output            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Miscalenous
theta = reshape(theta,[M nb_diffs]);
all_median = reshape(all_median,[M nb_diffs]);
all_std = reshape(all_std,[M nb_diffs]);

for num_d = 1:size(diffs,1)
    results.tests(num_d).plugin = theta(:,num_d);
    results.tests(num_d).median = all_median(:,num_d);
    results.tests(num_d).std = all_std(:,num_d);
end

% Results on PCE
results.bins_measure = bins_measure;
y = reshape(y,[length(bins_measure) M nb_diffs nb_iterations]);
PCE = reshape(PCE,[M nb_diffs nb_iterations]);
for num_d = 1:size(diffs,1)
    results.tests(num_d).diff = diffs(num_d,:);
    results.tests(num_d).cdf = squeeze(y(:,:,num_d,:));
    results.tests(num_d).PCE = squeeze(PCE(:,num_d,:));
end

% Results on FDR
results.bins_pce = bins_pce;
if flag_FDR == 1    
    results.FDR_dist = FDR_dist;
    results.FDR = FDR;
end

el_time = toc;
results.elapsed_time_s = el_time;